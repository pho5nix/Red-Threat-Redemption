# pfSense Logs Integration (Syslog and Suricata EVE JSON)
---
## Configure pfSense Logs Forwarding
### System Logs (Built-in Syslog)
In pfSense UI:  
- Go to **Status > System Logs > Settings**.  
- Under **Remote Logging**, enable **Send log messages to remote syslog server**.  
- Add remote server: `YOUR_DEBIAN_IP:5514` (UDP, default facility/levels are fine; use RFC5424 for better timestamps).  
- Select categories to forward (e.g., Firewall, System, DHCP).  
- Save and Apply.  

### Suricata Logs (via Syslog-ng Package)
Install syslog-ng package in pfSense:  
- Go to **System > Package Manager > Available Packages**.  
- Search for and install **syslog-ng**.  

Configure syslog-ng for Suricata EVE JSON:  
- Go to **Services > Syslog-ng > Advanced**.  
- Add a source:
  1. Object Name: s_suricata
  2. Object Type: Source
  3. Objject Parameters:
     ```
     {
       wildcard-file(
         base-dir("/var/log/suricata/")
         filename-pattern("eve.json")
         recursive(yes)
         flags(no-parse)
       );
     };
     ```
- Add a destination:
  1. Object Name: d_vector
  2. Object Type: Destination
  3. Object Parameters:
     ```
     {
          udp("YOUR-DEBIAN-IP" port(6000));
     };
     ```
- Add a log path:
  1. Object Name: log_suricata
  2. Object Type: Log
  3. Object Parameters:
     ```
     { source(s_suricata); destination(d_vector); };
     ```  
- Enable JSON forwarding.  
- Apply changes.  


## Configure Vector for pfSense Logs
Vector will receive: standard pfSense system logs on 5514 (UDP) and Suricata EVE JSON on 6000 (UDP). No additional installation needed (Vector already installed).

## Create Vector Pipeline
Append or create new sources/transforms/sinks in `/etc/vector/vector.yaml`:  
```
data_dir: /var/lib/vector

sources:
  pfsense_syslog:
    type: syslog
    mode: udp
    address: 0.0.0.0:5514
    max_message_size: 102400  # Updated from max_length

  suricata_eve:
    type: socket
    mode: udp
    address: 0.0.0.0:6000

  zeek_logs:
    type: file
    include:
      - /opt/zeek/logs/current/*.log
    read_from: end

  wazuh_alerts:
    type: file
    include:
      - /var/ossec/logs/alerts/alerts.json
    read_from: end
    ignore_checkpoints: false

transforms:
  pfsense_filterlog:
    type: remap
    inputs: [pfsense_syslog]
    source: |
      if !exists(.appname) || downcase(string!(.appname)) != "filterlog" { abort }
      msg = string!(.message)
      if !match(msg, r'^\d+,') { abort }
      cols = parse_csv!(msg)
      if length(cols) < 22 { abort }
      rule_s = string!(cols[0])
      subrule_s = string!(cols[1])
      iface = string!(cols[4])
      reason = string!(cols[5])
      action = string!(cols[6])
      direction = string!(cols[7])
      ipver_s = string!(cols[8])
      ttl_s = string!(cols[11])
      proto_id_s = string!(cols[15])
      proto_s = string!(cols[16])
      length_s = string!(cols[17])
      src_ip = string!(cols[18])
      dst_ip = string!(cols[19])
      src_port_s = string!(cols[20])
      dst_port_s = string!(cols[21])
      .pfsense.iface = iface
      .pfsense.reason = reason
      .pfsense.action = action
      .pfsense.direction = direction
      if match(rule_s, r'^\d+$') { .pfsense.rule = to_int!(rule_s) }
      if match(subrule_s, r'^\d+$') { .pfsense.subrule = to_int!(subrule_s) }
      if match(ipver_s, r'^\d+$') { .network.iana_number = to_int!(ipver_s) }
      if match(ttl_s, r'^\d+$') { .pfsense.ttl = to_int!(ttl_s) }
      if match(length_s, r'^\d+$') { .network.bytes = to_int!(length_s) }
      if match(proto_id_s, r'^\d+$') { .pfsense.proto_id = to_int!(proto_id_s) } else if proto_id_s != "" { .pfsense.proto_id_raw = proto_id_s }
      if match(src_port_s, r'^\d+$') { .source.port = to_int!(src_port_s) }
      if match(dst_port_s, r'^\d+$') { .destination.port = to_int!(dst_port_s) }
      .source.ip = src_ip
      .destination.ip = dst_ip
      if proto_s != "" { .network.transport = downcase(proto_s) }
      .event.category = ["network"]
      .event.type = ["connection"]
      .observer.product = "pfSense"
      if !exists(.tags) || !is_array(.tags) { .tags = [] }
      .tags = push!(.tags, "source_pfsense")

  suricata_parse:
    type: remap
    inputs: [suricata_eve]
    source: |
      parsed = parse_json(.message) ?? {}
      if is_object(parsed) {
        .suricata = parsed
      } else {
        abort
      }
      # promote timestamp
      if exists(.suricata.timestamp) {
        ."@timestamp" = parse_timestamp!(.suricata.timestamp, "%+")
      }
      # basic ECS mapping
      if exists(.suricata.src_ip) { .source.ip = .suricata.src_ip }
      if exists(.suricata.dest_ip) { .destination.ip = .suricata.dest_ip }
      if exists(.suricata.src_port) { .source.port = to_int(.suricata.src_port) ?? 0 }
      if exists(.suricata.dest_port) { .destination.port = to_int(.suricata.dest_port) ?? 0 }
      if exists(.suricata.proto) { .network.transport = downcase!(.suricata.proto) }
      if exists(.suricata.alert.signature_id) { .rule.id = to_string(.suricata.alert.signature_id) ?? "" }
      if exists(.suricata.alert.signature) { .rule.name = .suricata.alert.signature }
      if exists(.suricata.alert.severity) { .event.severity = to_int(.suricata.alert.severity) ?? 0 }
      .event.category = ["network"]
      .event.kind = "alert"
      .observer.product = "Suricata"
      if !exists(.tags) || !is_array(.tags) { .tags = [] }
      .tags = push!(.tags, "source_suricata")
      del(.message)

  zeek_parse:
    type: remap
    inputs: [zeek_logs]
    source: |
      .zeek = parse_json!(.message)
      if exists(.zeek.ts) { ."@timestamp" = is_timestamp(.zeek.ts) }
      if exists(.zeek.id.orig_h) { .source.ip = .zeek.id.orig_h }
      if exists(.zeek.id.resp_h) { .destination.ip = .zeek.id.resp_h }
      if exists(.zeek.id.orig_p) { .source.port = to_int!(.zeek.id.orig_p) }
      if exists(.zeek.id.resp_p) { .destination.port = to_int!(.zeek.id.resp_p) }
      if exists(.zeek.proto) { .network.transport = downcase!(.zeek.proto) }
      .event.category = ["network"]
      .observer.product = "Zeek"
      if !exists(.tags) || !is_array(.tags) { .tags = [] }
      .tags = push!(.tags, "source_zeek")

  wazuh_parse:
    type: remap
    inputs: [wazuh_alerts]
    source: |
      # Parse JSON line
      .wazuh = parse_json!(.message)
      if !exists(.tags) || !is_array(.tags) { .tags = [] }
      .tags = push!(.tags, "source_wazuh")
      # timestamp -> @timestamp
      if exists(.wazuh.timestamp) {
        ."@timestamp" = parse_timestamp!(.wazuh.timestamp, "%+")
        del(.wazuh.timestamp)
      }
      # Force stable numeric types
      if exists(.wazuh.rule.level) { .wazuh.rule.level = to_int!(.wazuh.rule.level) }
      if exists(.wazuh.rule.firedtimes) { .wazuh.rule.firedtimes = to_int!(.wazuh.rule.firedtimes) }
      if exists(.wazuh.rule.frequency) { .wazuh.rule.frequency = to_int!(.wazuh.rule.frequency) }
      # ECS mapping
      if exists(.wazuh.agent.name) { .host.name = .wazuh.agent.name }
      if exists(.wazuh.agent.id) { .host.id = .wazuh.agent.id }
      # rule.id as string for stability
      if exists(.wazuh.rule.id) { .rule.id = to_string!(.wazuh.rule.id) }
      # rule.name from description
      if exists(.wazuh.rule.description) { .rule.name = .wazuh.rule.description }
      # event typing/severity
      if exists(.wazuh.rule.level) {
        .event.kind = "alert"
        .event.category = ["host"]
        .event.severity = .wazuh.rule.level
      }

sinks:
  es_pfsense:
    type: elasticsearch
    inputs: [pfsense_filterlog]
    endpoints: ["https://localhost:9200"]
    auth:
      strategy: basic
      user: elastic
      password: ${ELASTIC_PASSWORD}
    tls:
      verify_certificate: true
      verify_hostname: true
      ca_file: /etc/vector/elasticsearch-ca.crt
    bulk:
      index: "pfsense-ecs-%Y.%m.%d"
    buffer:
      type: disk
      max_size: 5368709120
      when_full: block
    batch:
      max_bytes: 10000000
      timeout_secs: 1

  es_suricata:
    type: elasticsearch
    inputs: [suricata_parse]
    endpoints: ["https://localhost:9200"]
    auth:
      strategy: basic
      user: elastic
      password: ${ELASTIC_PASSWORD}
    tls:
      verify_certificate: true
      verify_hostname: true
      ca_file: /etc/vector/elasticsearch-ca.crt
    bulk:
      index: "suricata-ecs-%Y.%m.%d"
    buffer:
      type: disk
      max_size: 5368709120
      when_full: block
    batch:
      max_bytes: 10000000
      timeout_secs: 1

  es_zeek:
    type: elasticsearch
    inputs: [zeek_parse]
    endpoints: ["https://localhost:9200"]
    auth:
      strategy: basic
      user: elastic
      password: ${ELASTIC_PASSWORD}
    tls:
      verify_certificate: true
      verify_hostname: true
      ca_file: /etc/vector/elasticsearch-ca.crt
    bulk:
      index: "zeek-ecs-%Y.%m.%d"

  es_wazuh_alerts:
    type: elasticsearch
    inputs: [wazuh_parse]
    endpoints: ["https://localhost:9200"]
    auth:
      strategy: basic
      user: elastic
      password: ${ELASTIC_PASSWORD}
    tls:
      verify_certificate: true
      verify_hostname: true
      ca_file: /etc/vector/elasticsearch-ca.crt
    bulk:
      index: "wazuh-alerts-ecs-%Y.%m.%d"
    buffer:
      type: disk
      max_size: 5368709120
      when_full: block
    batch:
      max_bytes: 10000000
      timeout_secs: 1
```

## Restart Vector and Watch for Errors
```
sudo systemctl restart vector
```
```
sudo journalctl -u vector -n 50 --no-pager
```  
Look for successful reception and parsing (no parse errors).

## Check if Indices Exist
```
sudo curl --cacert /etc/kibana/http_ca.crt -u elastic https://localhost:9200/_cat/indices/pfsense-logs-*?v
```
```
sudo curl --cacert /etc/kibana/http_ca.crt -u elastic https://localhost:9200/_cat/indices/pfsense-suricata-*?v
```

## Create Kibana Data Views for pfSense
Access Kibana  
Open your browser and go to https://YOUR_SERVER_IP:5601  
Log in with the elastic user and password  

## Navigate to Stack Management  
Step | Action
|----|--------|
 1 | Click the hamburger menu (☰)
 2 | Go to Management → Stack Management
 3 | Click Kibana → Data Views

## Create pfSense syslog Data View
1. Click "Create data view"  
2. Configure the data view:  

Name: pfSense Logs  
Index pattern: pfsense-logs-*  
Timestamp field: @timestamp  

3. Click "Save data view to Kibana"  

## Create pfSense Suricata Data View  
1. Click "Create data view"  
2. Configure the data view:  

Name: pfSense Suricata Events  
Index pattern: pfsense-suricata-*  
Timestamp field: @timestamp  

3. Click "Save data view to Kibana"  

## Verify Data
Go to Analytics → Discover  
Select your "pfSense Logs" data view  
You should see system logs appearing in real-time. Filter examples:  
host.hostname : "your_pfsense_host"  
message : "filterlog"  # For firewall logs  

Select your "pfSense Suricata Events" data view  
You should see Suricata EVE events. Filter examples:  
event_type : "alert"  
event_type : "dns"  
community_id : *  
